{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation データの変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation Factoryを利用して作成した Annotation データを、SSD (Single Shot Multibox Detector) で学習できる形式に変換します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "業務で蓄積したデータは、機械学習に適した構造になっていないことがあります。  \n",
    "機械学習の業務では、そうしたデータを機械学習フレームワークが扱いやすい構造に変換することが頻繁にあります。  \n",
    "\n",
    "このノートブックでは、そうした変換を体験してみます。  \n",
    "例として、Annotation Factory（以降、AF と略記）で作成した汎用的な Annotation（教師データ）を、TensorFlow Object Detection Models（以降、TF Object Detection と略記）の SSD (Single Shot Multibox Detector) モデルで学習できる形式に変換します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../models/research/object_detection')\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from utils import dataset_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※ノートブックインスタンス起動直後は、少し時間がかかる場合があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AFのJSON構造"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AFの出力したAnnotationデータ（.json ファイル）を読み込んで、構造を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"./data-manabiya/width1000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printRecursive(obj, depth=0):\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            spacer = \"  \" * depth\n",
    "            print(\"{}{}: {}\".format(spacer, k, type(v)))\n",
    "            printRecursive(v, depth + 1)\n",
    "    if isinstance(obj,list):\n",
    "        for v in obj:\n",
    "            printRecursive(v, depth + 1)\n",
    "            \n",
    "            \n",
    "for annotation_json_path in glob.glob(data_path + \"json/*.json\"):\n",
    "    print(annotation_json_path)\n",
    "    json_dict = json.load(open(annotation_json_path, 'r'))\n",
    "    printRecursive(json_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AFで作成されるアノテーションJSONは、現在はこのような構造をしています。\n",
    "\n",
    "```\n",
    "input_data_id: <type 'unicode'>\n",
    "comment: <type 'unicode'>\n",
    "task_id: <type 'unicode'>\n",
    "detail: <type 'list'>\n",
    "        comment: <type 'unicode'>\n",
    "        user_id: <type 'unicode'>\n",
    "        account_id: <type 'unicode'>\n",
    "        annotation_id: <type 'unicode'>\n",
    "        label_name: <type 'unicode'>\n",
    "        label_id: <type 'unicode'>\n",
    "        data_holding_type: <type 'unicode'>\n",
    "        data: <type 'unicode'>\n",
    "        additional_data_list: <type 'list'>\n",
    "                type: <type 'unicode'>\n",
    "                choice: <type 'unicode'>\n",
    "                additional_data_definition_name: <type 'unicode'>\n",
    "                choice_name: <type 'unicode'>\n",
    "                additional_data_definition_id: <type 'unicode'>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF Object Detection に自分のデータセットを学習させるためには、データを TFRecords という形式にする必要があります。  \n",
    "https://www.tensorflow.org/api_guides/python/python_io#tfrecords_format_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSDのデータセット構造"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF Object Detection に用意されている TFRecords のファイルを読み込んで、構造を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_example_type = re.compile(\"^(\\S+)\\s\")\n",
    "re_example_value = re.compile(\"^\\S+\\s\\{\\n\\s+value:(.*)\\n\\}\")\n",
    "\n",
    "def truncate(s, limit):\n",
    "    if len(s) > limit:\n",
    "        return s[:limit] + \"... (truncated)\"\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "for record in tf.python_io.tf_record_iterator(\"../models/research/object_detection/test_data/pets_examples.record\"):\n",
    "    example = tf.train.Example.FromString(record)\n",
    "    \n",
    "    print(\"見本:\")\n",
    "    for key in sorted(example.features.feature):\n",
    "        v = example.features.feature[key]\n",
    "        vtype = re_example_type.search(str(v)).group(0)\n",
    "        vvalue = re_example_value.search(str(v)).group(1)\n",
    "        print(\"  {}: {} = {}\".format(key, vtype, truncate(vvalue, 50)))\n",
    "\n",
    "    print(\"raw:\")\n",
    "    for key in sorted(example.features.feature):\n",
    "        v = example.features.feature[key]\n",
    "        print(\"  {}: {}\".format(key, v))\n",
    "\n",
    "    # 型と見本を見たいだけなので1個で終了    \n",
    "    break    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のアノテーションJSONを、TFRecordsに変換していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"指定した点を全て含む矩形（＝Bounding Box）を返す。\"\"\"\n",
    "def bounding_box(coordinates):\n",
    "    _x = 0\n",
    "    _y = 1\n",
    "    _xs = [t[_x] for t in coordinates]\n",
    "    _ys = [t[_y] for t in coordinates]\n",
    "    min_x, min_y = min(_xs), min(_ys)\n",
    "    max_x, max_y = max(_xs), max(_ys)\n",
    "    return (min_x, min_y, max_x, max_y)\n",
    "\n",
    "bounding_box([(1,1), (2,4), (3,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input_data_id と ファイル名の対応辞書を作成します。今回は、全体の画像のうち、\n",
    "* 80% 学習用（train）\n",
    "* 20% 評価用（eval）\n",
    "に分けます。恣意性が入らないようにランダムに分けます\"\"\"\n",
    "\n",
    "import random \n",
    "random.seed(20180323)\n",
    "\n",
    "inputs_json_path = data_path + \"inputs.json\"         \n",
    "inputs_json_dict = json.load(open(inputs_json_path, 'r'))\n",
    "input_data_list = inputs_json_dict[\"list\"]\n",
    "random.shuffle(input_data_list)\n",
    "\n",
    "needle_80 = int(len(input_data_list) * 0.8)\n",
    "(for_train, for_eval) = input_data_list[0:needle_80], input_data_list[needle_80:]\n",
    "\n",
    "def to_id_name_mapping(input_data_list):\n",
    "    return {str(e[\"input_data_id\"]): str(e[\"input_data_name\"])  for e in input_data_list}\n",
    "\n",
    "input_data_id_2_input_name = {\n",
    "    \"train\": to_id_name_mapping(for_train),\n",
    "    \"eval\": to_id_name_mapping(for_eval),\n",
    "}\n",
    "input_data_id_2_input_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 後で利用するために「input_data_id と ファイル名の対応辞書」をファイルに出力\n",
    "dict_filepath = \"./input_data_id_2_input_name.json\"\n",
    "with open(dict_filepath, \"w\") as out_fp:\n",
    "    json.dump(input_data_id_2_input_name, out_fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"クラス名とインデックス（1-origin）の対応辞書\"\"\"\n",
    "class_text_2_index = {label: index for (index, label) in enumerate([\n",
    "    \"january-normal\", \"january-poetry-ribbon\", \"january-special-crane-and-sun\",\n",
    "    \"february-normal\", \"february-poetry-ribbon\", \"february-special-bush-warbler-in-a-tree\",\n",
    "    \"march-normal\", \"march-poetry-ribbon\", \"march-special-camp-curtain\",\n",
    "    \"april-normal\", \"april-red-ribbon\", \"april-special-cuckoo\",\n",
    "    \"may-normal\", \"may-red-ribbon\", \"may-special-water-irs-and-eight-plank-bridge\",\n",
    "    \"june-normal\", \"june-purple-ribbon\", \"june-special-butterflies\",\n",
    "    \"july-normal\", \"july-red-ribbon\", \"july-special-boar\", \n",
    "    \"august-normal\", \"august-special-geese-in-flight\", \"august-special-full-moon-with-red-sky\",\n",
    "    \"september-normal\", \"september-purple-ribbon\", \"september-special-poetry-sake-cup\",\n",
    "    \"october-normal\", \"october-purple-ribbon\", \"october-special-deer-and-maple\",\n",
    "    \"november-red-ribbon\", \"november-special-lightning\", \"november-special-swallow\", \"november-special-rainman-with-umbrella-and-frog\",\n",
    "    \"december-normal\", \"december-special-chinese-phoenix\"\n",
    "], 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"画像を読み込んでPNGエンコードしたバイト列を返す。\"\"\"\n",
    "def byte_encode_image(imagepath):\n",
    "    import io \n",
    "    from PIL import Image\n",
    "\n",
    "    with open(imagepath, \"r\") as imageFile:\n",
    "        img = Image.open(imageFile, mode='r')    \n",
    "        imgByteArr = io.BytesIO()\n",
    "        img.save(imgByteArr, format='PNG')\n",
    "        return imgByteArr.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def generate_tfrecord(out_path, id_2_name_mapping):\n",
    "    with tf.python_io.TFRecordWriter(out_path) as writer:\n",
    "        for annotation_json_path in glob.glob(data_path + \"json/*.json\"):\n",
    "            json_dict = json.load(open(annotation_json_path, 'r'))\n",
    "            filename = id_2_name_mapping.get(json_dict[\"input_data_id\"], None)\n",
    "            if (filename is None):\n",
    "                continue\n",
    "            \n",
    "            image_path = data_path + \"image/{}\".format(filename)\n",
    "            # 画像サイズは決め打ち\n",
    "            width,height = 1000.0, 750.0\n",
    "            encoded_image_data = byte_encode_image(image_path)\n",
    "\n",
    "            # 1画像内の複数アノテーションを扱うため配列\n",
    "            xmins = []\n",
    "            xmaxs = []\n",
    "            ymins = []\n",
    "            ymaxs = []\n",
    "            classes_text = []\n",
    "            classes = []\n",
    "\n",
    "            for annotation in json_dict[\"detail\"]:           \n",
    "                xy_coordinates = [(int(e[\"x\"]),int(e[\"y\"])) for e in annotation[\"data\"]]\n",
    "                min_x, min_y, max_x, max_y = bounding_box(xy_coordinates)\n",
    "                xmins.append(min_x / width)\n",
    "                ymins.append(min_y / height)\n",
    "                xmaxs.append(max_x / width)\n",
    "                ymaxs.append(max_y / height)\n",
    "                class_text = str(annotation[\"additional_data_list\"][0][\"choice\"])\n",
    "                classes_text.append(class_text)\n",
    "                classes.append(class_text_2_index[class_text])\n",
    "\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'image/height': dataset_util.int64_feature(int(height)),\n",
    "                'image/width': dataset_util.int64_feature(int(width)),\n",
    "                'image/filename': dataset_util.bytes_feature(filename),\n",
    "                'image/source_id': dataset_util.bytes_feature(filename),\n",
    "                'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "                'image/format': dataset_util.bytes_feature(\"png\"),\n",
    "                'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "                'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "                'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "                'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "                'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "                'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "            }))\n",
    "            writer.write(example.SerializeToString())\n",
    "            \n",
    "# 変換実施\n",
    "generate_tfrecord(\"af_dataset_train.record\", input_data_id_2_input_name[\"train\"])\n",
    "generate_tfrecord(\"af_dataset_eval.record\", input_data_id_2_input_name[\"eval\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ラベルマップ出力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ラベルマップは、TF Object Detection の学習（訓練・検証）で利用する、クラスIDとクラス名の対応を記述したファイルです。  \n",
    "アノテーションJSONをTFRecordsに変換する際に用意した「クラス名とインデックス（1-origin）の対応辞書」を、このラベルマップに変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 辞書の変換\n",
    "index_2_class_text = {index: label for (label, index) in class_text_2_index.items()}\n",
    "index_2_class_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ラベルマップファイル名\n",
    "label_map_filepath = \"label_map.pbtxt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 出力\n",
    "with open(label_map_filepath, \"w\") as f:\n",
    "    for index in sorted(index_2_class_text.keys()):\n",
    "        label = index_2_class_text[index]\n",
    "        f.write(\"item {\\n\")\n",
    "        f.write(\"  id: {}\\n\".format(index))\n",
    "        f.write(\"  name: '{}'\\n\".format(label))\n",
    "        f.write(\"}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
